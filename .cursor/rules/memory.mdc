---
description: 
globs: 
alwaysApply: false
---
BufferWindowMemory(k=1) ，都使上下文恒定大小（固定一轮的上下文），因此 Prompt 大小不会随轮次增加，也就不会带来多余的 token 花费或性能下降。

如果你用普通的 BufferMemory（不裁剪），对话越多，Prompt 会越来越长，确实会越来越慢、成本也会攀升；但用「只保留一条」的策略，完全规避了这个问题。

保留「上一次生成代码」——BufferWindowMemory
原理
BufferWindowMemory 只保留最近 K 次交互。在这里，将 k 设为 1，即只保留“上一轮”用户输入和 AI 输出（即上次生成的代码） Agent 中同时实现「仅保留上一轮生成代码需求，保证多轮代码迭代的上下文连贯。这确保了Agent在多轮交互中能够记住之前的上下文，提供连贯的代码生成体验